{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc06a70",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import entropy\n",
    "from pysteps.verification.probscores import CRPS\n",
    "from pysteps.verification.salscores import sal\n",
    "from pysteps.verification.spatialscores import fss\n",
    "from pysteps.verification.rankhist import rankhist\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf16af-7a4b-49ec-b2fb-32290fee3403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "##########  Observation vs Simulation COMPARISON  ###########\n",
    "#############################################################\n",
    "\n",
    "\n",
    "def read_raster(file_path, time_step):\n",
    "    data = xr.open_dataset(file_path)\n",
    "    return data[\"sequence\"].isel(timestep=time_step)  \n",
    "\n",
    "orario_specificato = \"2023-10-31T03:00:00\"  # SELECTED FILE\n",
    "durata_minuti = 100  \n",
    "intervallo_minuti = 20  \n",
    "num_membri = list(range(20)) \n",
    "\n",
    "ldcast_dir = Path(\"../../ens/oct_ld_ens\")\n",
    "gptcast_dir = Path(\"../../ens/oct_gpt_ens\")\n",
    "\n",
    "file_list = sorted(ldcast_dir.glob(\"*.nc\"))\n",
    "file_specificato = None\n",
    "for file in file_list:\n",
    "    if orario_specificato in file.name:\n",
    "        file_specificato = file\n",
    "        break\n",
    "\n",
    "if file_specificato is None:\n",
    "    raise ValueError(f\"No file for time: {orario_specificato}\")\n",
    "\n",
    "ds_specificato = xr.open_dataset(file_specificato)\n",
    "raster_osservato = read_raster(file_specificato, time_step=3)\n",
    "\n",
    "orario_iniziale = datetime.strptime(orario_specificato, \"%Y-%m-%dT%H:%M:%S\")\n",
    "file_paths = []\n",
    "for minuto in range(0, durata_minuti + 1, intervallo_minuti):\n",
    "    orario_corrente = orario_iniziale + timedelta(minutes=minuto)\n",
    "    file_name = f\"{orario_corrente.strftime('%Y-%m-%dT%H:%M:%S')}_0_utm32n.nc\"  # MEMBER 0\n",
    "    file_paths.append(file_name)\n",
    "\n",
    "fig, axes = plt.subplots(3, len(file_paths), figsize=(15, 9), constrained_layout=True)\n",
    "\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    ld_file_path = ldcast_dir / file_path  \n",
    "    if not ld_file_path.exists():\n",
    "        raise ValueError(f\"No file LDCast: {ld_file_path}\")\n",
    "    raster = read_raster(ld_file_path, time_step=3)\n",
    "    im = axes[0, i].imshow(raster, cmap=\"turbo\", norm=LogNorm(vmin=1e-1, vmax=1e2))\n",
    "    axes[0, i].set_title(f\"+{i * intervallo_minuti} min\", fontsize=16)\n",
    "    axes[0, i].grid(True, color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
    "    axes[0, i].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)  \n",
    "\n",
    "time_steps_ldcast = [7, 11, 15, 19, 23]\n",
    "for i, time_step in enumerate(time_steps_ldcast):\n",
    "    raster = read_raster(file_specificato, time_step=time_step)\n",
    "\n",
    "    data_values = raster.values\n",
    "    if data_values.ndim >= 2 and not np.isnan(data_values).all():  \n",
    "        rotated_data = np.rot90(data_values, k=+1, axes=(0, 1))  \n",
    "        mirrored_data = rotated_data[::-1, :] \n",
    "        raster.values = mirrored_data  \n",
    "\n",
    "    im = axes[1, i + 1].imshow(raster, cmap=\"turbo\", norm=LogNorm(vmin=1e-1, vmax=1e2)) \n",
    "    axes[1, i + 1].grid(True, color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
    "    axes[1, i + 1].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)  \n",
    "    \n",
    "time_steps_gptcast = [7, 11, 15, 19, 23]\n",
    "for i, time_step in enumerate(time_steps_gptcast):\n",
    "    gpt_file = gptcast_dir / file_specificato.name  \n",
    "    if not gpt_file.exists():\n",
    "        raise ValueError(f\"No File GPTCast: {gpt_file}\")\n",
    "    raster = read_raster(gpt_file, time_step=time_step)\n",
    "\n",
    "    data_values = raster.values\n",
    "    if data_values.ndim >= 2 and not np.isnan(data_values).all():  \n",
    "        rotated_data = np.rot90(data_values, k=+1, axes=(0, 1))  \n",
    "        mirrored_data = rotated_data[::-1, :]  \n",
    "        raster.values = mirrored_data \n",
    "\n",
    "    im = axes[2, i + len(file_paths) - len(time_steps_gptcast)].imshow(raster, cmap=\"turbo\", norm=LogNorm(vmin=1e-1, vmax=1e2))\n",
    "    axes[2, i + len(file_paths) - len(time_steps_gptcast)].grid(True, color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
    "    axes[2, i + len(file_paths) - len(time_steps_gptcast)].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)  \n",
    "\n",
    "axes[1, 0].axis(\"off\")  \n",
    "axes[2, 0].axis(\"off\")  \n",
    "\n",
    "cbar = fig.colorbar(im, ax=axes[:, -1], orientation=\"vertical\", fraction=0.10, pad=0.08)  \n",
    "cbar.set_label(\"Intensity [mm h⁻¹]\", fontsize=16) \n",
    "cbar.ax.tick_params(labelsize=14)  \n",
    "\n",
    "axes[0, 0].set_ylabel(\"Observation\", fontsize=20)\n",
    "axes[1, len(file_paths) - len(time_steps_ldcast)].set_ylabel(\"LDCast\", fontsize=20)\n",
    "axes[2, len(file_paths) - len(time_steps_gptcast)].set_ylabel(\"GPTCast\", fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dfd654-43ba-4ebf-8194-035266b012d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "#################### CRPS COMPUTATION #######################\n",
    "#############################################################\n",
    "\n",
    "def apply_transformations(raster):\n",
    "    rotated = np.rot90(raster, k=+1, axes=(0, 1))  \n",
    "    mirrored = rotated[::-1, :]  \n",
    "    return mirrored\n",
    "\n",
    "orario_iniziale = \"2023-10-31T02:45:00\"  \n",
    "durata_minuti = 120  \n",
    "durata_calcolo = 240 # CRPS COMPUTATION DURATION\n",
    "intervallo_minuti = 5  \n",
    "num_membri = list(range(20))  \n",
    "\n",
    "ldcast_dir = Path(\"../../ens/oct_ld_ens\")\n",
    "gptcast_dir = Path(\"../../ens/oct_gpt_ens\")\n",
    "\n",
    "def find_file(directory, timestamp):\n",
    "    file_list = sorted(directory.glob(\"*.nc\"))\n",
    "    for file in file_list:\n",
    "        if timestamp in file.name:\n",
    "            return file\n",
    "    return None\n",
    "\n",
    "\n",
    "def create_observed_vector(orario_iniziale, durata_calcolo, intervallo_minuti, directory):\n",
    "    observed_vector = []\n",
    "    for minuto in range(0, durata_calcolo + 1, intervallo_minuti):\n",
    "        orario_corrente = datetime.strptime(orario_iniziale, \"%Y-%m-%dT%H:%M:%S\") + timedelta(minutes=minuto)\n",
    "        file_corrente = find_file(directory, orario_corrente.strftime(\"%Y-%m-%dT%H:%M:%S\"))\n",
    "        if file_corrente is None:\n",
    "            raise ValueError(f\"No file for time: {orario_corrente}\")\n",
    "        ds_corrente = xr.open_dataset(file_corrente)\n",
    "        raster_corrente = ds_corrente[\"sequence\"].isel(timestep=3).values\n",
    "        observed_vector.append(raster_corrente)\n",
    "    return observed_vector\n",
    "\n",
    "def create_lead_time_vector(orario_iniziale, durata_calcolo, intervallo_minuti, lead_time, directory, num_membri):\n",
    "    lead_time_vector = []\n",
    "    for minuto in range(0, durata_calcolo + 1, intervallo_minuti):\n",
    "        orario_corrente = datetime.strptime(orario_iniziale, \"%Y-%m-%dT%H:%M:%S\") - timedelta(minutes=lead_time - minuto)\n",
    "        timestep_corrente = 3 + (lead_time // intervallo_minuti)\n",
    "        ensemble_stack = []\n",
    "        for membro in num_membri:\n",
    "            file_membro = directory / f\"{orario_corrente.strftime('%Y-%m-%dT%H:%M:%S')}_{membro}_utm32n.nc\"\n",
    "            if not file_membro.exists():\n",
    "                continue\n",
    "            ds_membro = xr.open_dataset(file_membro)\n",
    "            if timestep_corrente >= ds_membro[\"sequence\"].shape[0]:\n",
    "                continue\n",
    "            raster_membro = ds_membro[\"sequence\"].isel(timestep=timestep_corrente).values\n",
    "            if raster_membro.ndim == 2:  \n",
    "                raster_membro = apply_transformations(raster_membro)\n",
    "                ensemble_stack.append({\n",
    "                    \"membro\": membro,\n",
    "                    \"timestep\": timestep_corrente,\n",
    "                    \"data\": raster_membro\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Error: ensemble member not 2D. Shape: {raster_membro.shape}\")\n",
    "        lead_time_vector.append({\n",
    "            \"timestamp\": orario_corrente,\n",
    "            \"ensemble\": ensemble_stack\n",
    "        })\n",
    "    return lead_time_vector\n",
    "\n",
    "def calculate_crps(observed_vector, lead_time_vector):\n",
    "    crps_results = []\n",
    "    for i, raster_osservato in enumerate(observed_vector):\n",
    "        ensemble_stack = []\n",
    "        for ensemble_entry in lead_time_vector[i][\"ensemble\"]:\n",
    "            raster_membro = ensemble_entry[\"data\"]\n",
    "            if raster_osservato.shape != raster_membro.shape:\n",
    "                raise ValueError(\n",
    "                    f\"Observed dimension {raster_osservato.shape} \"\n",
    "                    f\"do not correspond to simulated {raster_membro.shape}.\"\n",
    "                )\n",
    "            ensemble_stack.append(raster_membro)\n",
    "        \n",
    "        if len(ensemble_stack) > 0:\n",
    "            ensemble_stack = np.stack(ensemble_stack, axis=0)\n",
    "            crps_value = CRPS(ensemble_stack, raster_osservato)\n",
    "            crps_results.append(crps_value)\n",
    "    return crps_results\n",
    "\n",
    "results_crps = {\"LDCast\": {}, \"GPTCast\": {}}\n",
    "\n",
    "for model_name in results_crps.keys():\n",
    "    results_crps[model_name][0] = 0 \n",
    "\n",
    "for model_name, model_dir in [(\"LDCast\", ldcast_dir), (\"GPTCast\", gptcast_dir)]:\n",
    "    observed_vector = create_observed_vector(orario_iniziale, durata_minuti, intervallo_minuti, model_dir)\n",
    "    for lead_time in tqdm(range(5, durata_minuti + 1, intervallo_minuti), desc=f\"Lead time {model_name}\"):\n",
    "        lead_time_vector = create_lead_time_vector(orario_iniziale, durata_minuti, intervallo_minuti, lead_time, model_dir, num_membri)\n",
    "        crps_results = calculate_crps(observed_vector, lead_time_vector)\n",
    "        results_crps[model_name][lead_time] = crps_results\n",
    "\n",
    "# Risultati finali\n",
    "print(\"CRPS computation completed for both models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b7fef-ef94-47e5-952e-b0d32a654767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "######################## CRPS PLOT ##########################\n",
    "#############################################################\n",
    "\n",
    "for model_name in results_crps.keys():\n",
    "    results_crps[model_name][0] = [0]\n",
    "\n",
    "def plot_crps_with_dispersion(results_crps):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for model_name, color in zip(results_crps.keys(), [\"blue\", \"orange\"]):\n",
    "        crps_results = results_crps[model_name]  \n",
    "        lead_times = sorted(crps_results.keys()) \n",
    "        mean_crps = [] \n",
    "        std_crps = [] \n",
    "        for lead_time in lead_times:\n",
    "            crps_values = crps_results[lead_time]  \n",
    "            mean_crps.append(np.mean(crps_values))  \n",
    "            std_crps.append(np.std(crps_values)) \n",
    "\n",
    "            plt.scatter([lead_time] * len(crps_values), crps_values, color=color, alpha=0.5, label=f\"Values {model_name}\" if lead_time == lead_times[0] else \"\")\n",
    "\n",
    "        plt.plot(lead_times, mean_crps, color=color, linewidth=2, label=f\"Mean {model_name}\")\n",
    "\n",
    "        plt.fill_between(\n",
    "            lead_times,\n",
    "            np.array(mean_crps) - np.array(std_crps),\n",
    "            np.array(mean_crps) + np.array(std_crps),\n",
    "            color=color,\n",
    "            alpha=0.2,\n",
    "            label=f\"{model_name} (± std)\" if lead_time == lead_times[0] else \"\"\n",
    "        )\n",
    "\n",
    "    plt.title(\"CRPS evolution with Lead Time, October Case\", fontsize=18)\n",
    "    plt.xlabel(\"Lead Time [min]\", fontsize=16)\n",
    "    plt.ylabel(\"CRPS [mm h⁻¹]\", fontsize=16)\n",
    "    plt.grid()\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.tick_params(axis=\"both\", labelsize=15)  \n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_crps_with_dispersion(results_crps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f42a86f-5147-4693-a698-aa51d8f9615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "##################### SAL COMPUTATION #######################\n",
    "#############################################################\n",
    "\n",
    "def apply_transformations(raster):\n",
    "    rotated = np.rot90(raster, k=+1, axes=(0, 1))  \n",
    "    mirrored = rotated[::-1, :]  \n",
    "    return mirrored\n",
    "\n",
    "orario_iniziale = \"2023-10-31T02:45:00\"  \n",
    "durata_minuti = 120  \n",
    "durata_calcolo = 240 \n",
    "intervallo_minuti = 5  \n",
    "num_membri = list(range(20))  \n",
    "\n",
    "ldcast_dir = Path(\"../../ens/oct_ld_ens\")\n",
    "gptcast_dir = Path(\"../../ens/oct_gpt_ens\")\n",
    "\n",
    "def find_file(directory, timestamp):\n",
    "    file_list = sorted(directory.glob(\"*.nc\"))\n",
    "    for file in file_list:\n",
    "        if timestamp in file.name:\n",
    "            return file\n",
    "    return None\n",
    "\n",
    "def create_observed_vector(orario_iniziale, durata_calcolo, intervallo_minuti, directory):\n",
    "    observed_vector = []\n",
    "    for minuto in range(0, durata_calcolo + 1, intervallo_minuti):\n",
    "        orario_corrente = datetime.strptime(orario_iniziale, \"%Y-%m-%dT%H:%M:%S\") + timedelta(minutes=minuto)\n",
    "        file_corrente = find_file(directory, orario_corrente.strftime(\"%Y-%m-%dT%H:%M:%S\"))\n",
    "        if file_corrente is None:\n",
    "            raise ValueError(f\"No file for time: {orario_corrente}\")\n",
    "        ds_corrente = xr.open_dataset(file_corrente)\n",
    "        raster_corrente = ds_corrente[\"sequence\"].isel(timestep=3).values\n",
    "        observed_vector.append(raster_corrente)\n",
    "    return observed_vector\n",
    "\n",
    "def create_lead_time_vector(orario_iniziale, durata_calcolo, intervallo_minuti, lead_time, directory, num_membri):\n",
    "    lead_time_vector = []\n",
    "    for minuto in range(0, durata_calcolo + 1, intervallo_minuti):\n",
    "        orario_corrente = datetime.strptime(orario_iniziale, \"%Y-%m-%dT%H:%M:%S\") - timedelta(minutes=lead_time - minuto)\n",
    "        timestep_corrente = 3 + (lead_time // intervallo_minuti)\n",
    "        ensemble_stack = []\n",
    "        for membro in num_membri:\n",
    "            file_membro = directory / f\"{orario_corrente.strftime('%Y-%m-%dT%H:%M:%S')}_{membro}_utm32n.nc\"\n",
    "            if not file_membro.exists():\n",
    "                continue\n",
    "            ds_membro = xr.open_dataset(file_membro)\n",
    "            if timestep_corrente >= ds_membro[\"sequence\"].shape[0]:\n",
    "                continue\n",
    "            raster_membro = ds_membro[\"sequence\"].isel(timestep=timestep_corrente).values\n",
    "            if raster_membro.ndim == 2:  \n",
    "                raster_membro = apply_transformations(raster_membro)\n",
    "                ensemble_stack.append({\n",
    "                    \"membro\": membro,\n",
    "                    \"timestep\": timestep_corrente,\n",
    "                    \"data\": raster_membro\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Error: ensemble member not 2D. Shape: {raster_membro.shape}\")\n",
    "        lead_time_vector.append({\n",
    "            \"timestamp\": orario_corrente,\n",
    "            \"ensemble\": ensemble_stack\n",
    "        })\n",
    "    return lead_time_vector\n",
    "\n",
    "def calculate_sal(observed_vector, lead_time_vector):\n",
    "    sal_results = {\"S\": [], \"A\": [], \"L\": []}  \n",
    "    for i, raster_osservato in enumerate(observed_vector):\n",
    "        S_lead_time = []\n",
    "        A_lead_time = []\n",
    "        L_lead_time = []\n",
    "        for ensemble_entry in lead_time_vector[i][\"ensemble\"]:\n",
    "            raster_membro = ensemble_entry[\"data\"]\n",
    "            if raster_osservato.shape != raster_membro.shape:\n",
    "                raise ValueError(\n",
    "                    f\"Observed dimension {raster_osservato.shape} \"\n",
    "                    f\"do not correspond to simulated {raster_membro.shape}.\"\n",
    "                )\n",
    "            S, A, L = sal(raster_osservato, raster_membro)\n",
    "            S_lead_time.append(S)\n",
    "            A_lead_time.append(A)\n",
    "            L_lead_time.append(L)\n",
    "        if S_lead_time and A_lead_time and L_lead_time:\n",
    "            sal_results[\"S\"].append(np.mean(S_lead_time))\n",
    "            sal_results[\"A\"].append(np.mean(A_lead_time))\n",
    "            sal_results[\"L\"].append(np.mean(L_lead_time))\n",
    "    return sal_results\n",
    "\n",
    "results_sal = {\"LDCast\": {}, \"GPTCast\": {}}\n",
    "\n",
    "for model_name in results_sal.keys():\n",
    "    results_sal[model_name][0] = {\"S\": 0, \"A\": 0, \"L\": 0}  \n",
    "\n",
    "results_sal = {\"LDCast\": {}, \"GPTCast\": {}}\n",
    "for model_name, model_dir in [(\"LDCast\", ldcast_dir), (\"GPTCast\", gptcast_dir)]:\n",
    "    observed_vector = create_observed_vector(orario_iniziale, durata_minuti, intervallo_minuti, model_dir)\n",
    "    for lead_time in tqdm(range(5, durata_minuti + 1, intervallo_minuti), desc=f\"Lead time {model_name}\"):\n",
    "        lead_time_vector = create_lead_time_vector(orario_iniziale, durata_minuti, intervallo_minuti, lead_time, model_dir, num_membri)\n",
    "        sal_results = calculate_sal(observed_vector, lead_time_vector)\n",
    "        results_sal[model_name][lead_time] = sal_results\n",
    "\n",
    "print(\"SAL computation completed for both models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda6fef1-01dd-4672-a539-7537589927b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "######################### SAL PLOT ##########################\n",
    "#############################################################\n",
    "\n",
    "\n",
    "for model_name in results_sal.keys():\n",
    "    if 0 not in results_sal[model_name]:\n",
    "        results_sal[model_name][0] = {\"S\": [0], \"A\": [0], \"L\": [0]}  \n",
    "\n",
    "def plot_sal_components(results_sal, durata_minuti, intervallo_minuti):\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 12), sharex=True)\n",
    "    components = [\"S\", \"A\", \"L\"]\n",
    "    titles = [\"Structure [S]\", \"Amplitude [A]\", \"Location [L]\"]\n",
    "    colors = {\"LDCast\": \"blue\", \"GPTCast\": \"orange\"}\n",
    "    \n",
    "    for i, component in enumerate(components):\n",
    "        ax = axes[i]\n",
    "        for model_name, model_results in results_sal.items():\n",
    "            lead_times = sorted(model_results.keys())\n",
    "            mean_values = []\n",
    "            std_values = []\n",
    "            \n",
    "            for lead_time in lead_times:\n",
    "                values = model_results[lead_time][component]\n",
    "                mean_values.append(np.mean(values))\n",
    "                std_values.append(np.std(values))\n",
    "                \n",
    "                ax.scatter([lead_time] * len(values), values, color=colors[model_name], alpha=0.5, label=f\"Values {model_name}\" if lead_time == intervallo_minuti else \"\")\n",
    "            \n",
    "            ax.plot(lead_times, mean_values, color=colors[model_name], label=f\"Mean {model_name}\")\n",
    "            \n",
    "            ax.fill_between(lead_times, \n",
    "                            np.array(mean_values) - np.array(std_values), \n",
    "                            np.array(mean_values) + np.array(std_values), \n",
    "                            color=colors[model_name], alpha=0.3)\n",
    "        \n",
    "        ax.set_title(f\"{titles[i]}, October Case\", fontsize=14)\n",
    "        \n",
    "        ax.set_ylabel(f\"{component} [-]\", fontsize=16)\n",
    "        \n",
    "        if component in [\"S\", \"A\"]:\n",
    "            ax.set_ylim(-2, 2) \n",
    "        elif component == \"L\":\n",
    "            ax.set_ylim(0, 2) \n",
    "        \n",
    "        ax.tick_params(axis=\"both\", labelsize=14)\n",
    "        \n",
    "        if component == \"A\":\n",
    "            ax.legend(loc=\"lower left\", fontsize=14)  \n",
    "        else:\n",
    "            ax.legend(loc=\"upper left\", fontsize=14) \n",
    "        ax.grid(True)\n",
    "    \n",
    "    axes[-1].set_xlabel(\"Lead Time [min]\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])  \n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_sal_components(results_sal, durata_minuti, intervallo_minuti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f407a12b-3a4c-4061-baa7-b4ea551f1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "#################### FSS COMPUTATION ########################\n",
    "#############################################################\n",
    "\n",
    "def apply_transformations(raster):\n",
    "    rotated = np.rot90(raster, k=+1, axes=(0, 1))  \n",
    "    mirrored = rotated[::-1, :] \n",
    "    return mirrored\n",
    "\n",
    "orario_iniziale = \"2023-10-31T02:45:00\"  \n",
    "durata_minuti = 120  \n",
    "durata_calcolo = 240 \n",
    "intervallo_minuti = 5  \n",
    "num_membri = list(range(20))  \n",
    "\n",
    "ldcast_dir = Path(\"../../ens/oct_ld_ens\")\n",
    "gptcast_dir = Path(\"../../ens/oct_gpt_ens\")\n",
    "\n",
    "finestre_spaziali = [1, 8, 14, 64, 128, 267]  # SPATIAL WINDOW\n",
    "soglie = [0.1, 2.5, 10] # THRESHOLDS\n",
    "\n",
    "def find_file(directory, timestamp):\n",
    "    file_list = sorted(directory.glob(\"*.nc\"))\n",
    "    for file in file_list:\n",
    "        if timestamp in file.name:\n",
    "            return file\n",
    "    return None\n",
    "\n",
    "def create_observed_vector(orario_iniziale, durata_calcolo, intervallo_minuti, directory, num_membri):\n",
    "    observed_vector = []\n",
    "    for minuto in range(0, durata_calcolo + 1, intervallo_minuti):\n",
    "        orario_corrente = datetime.strptime(orario_iniziale, \"%Y-%m-%dT%H:%M:%S\") + timedelta(minutes=minuto)\n",
    "        file_corrente = find_file(directory, orario_corrente.strftime(\"%Y-%m-%dT%H:%M:%S\"))\n",
    "        if file_corrente is None:\n",
    "            raise ValueError(f\"No file for time: {orario_corrente}\")\n",
    "        ds_corrente = xr.open_dataset(file_corrente)\n",
    "        raster_corrente = ds_corrente[\"sequence\"].isel(timestep=3).values\n",
    "        observed_vector.append(raster_corrente)\n",
    "    return observed_vector\n",
    "\n",
    "def create_lead_time_vector(orario_iniziale, durata_calcolo, intervallo_minuti, lead_time, directory, num_membri):\n",
    "    lead_time_vector = []\n",
    "    for minuto in range(0, durata_calcolo + 1, intervallo_minuti):\n",
    "        orario_corrente = datetime.strptime(orario_iniziale, \"%Y-%m-%dT%H:%M:%S\") - timedelta(minutes=lead_time - minuto)\n",
    "        timestep_corrente = 3 + (lead_time // intervallo_minuti)\n",
    "        ensemble_stack = []\n",
    "        for membro in num_membri:\n",
    "            file_membro = directory / f\"{orario_corrente.strftime('%Y-%m-%dT%H:%M:%S')}_{membro}_utm32n.nc\"\n",
    "            if not file_membro.exists():\n",
    "                continue\n",
    "            ds_membro = xr.open_dataset(file_membro)\n",
    "            if timestep_corrente >= ds_membro[\"sequence\"].shape[0]:\n",
    "                continue\n",
    "            raster_membro = ds_membro[\"sequence\"].isel(timestep=timestep_corrente).values\n",
    "            if raster_membro.ndim == 2:  \n",
    "                raster_membro = apply_transformations(raster_membro)\n",
    "                ensemble_stack.append({\n",
    "                    \"membro\": membro,\n",
    "                    \"timestep\": timestep_corrente,\n",
    "                    \"data\": raster_membro\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Error: ensemble member not 2D. Shape: {raster_membro.shape}\")\n",
    "        lead_time_vector.append({\n",
    "            \"timestamp\": orario_corrente,\n",
    "            \"ensemble\": ensemble_stack\n",
    "        })\n",
    "    return lead_time_vector\n",
    "\n",
    "def calculate_fss(observed_vector, lead_time_vector, finestre_spaziali, soglie):\n",
    "    fss_results = {window: {threshold: [] for threshold in soglie} for window in finestre_spaziali}\n",
    "    for i, raster_osservato in enumerate(observed_vector):\n",
    "        if \"ensemble\" not in lead_time_vector[i] or not lead_time_vector[i][\"ensemble\"]:\n",
    "            print(f\"Attention: no ensemble for lead time[{i}]\")\n",
    "            continue\n",
    "        \n",
    "        for window in finestre_spaziali:\n",
    "            for threshold in soglie:\n",
    "                fss_lead_time = []\n",
    "                for ensemble_entry in lead_time_vector[i][\"ensemble\"]:\n",
    "                    raster_membro = ensemble_entry[\"data\"]\n",
    "                    if raster_osservato.shape != raster_membro.shape:\n",
    "                        raise ValueError(\n",
    "                            f\"Observed dimension {raster_osservato.shape} \"\n",
    "                            f\"do not correspond to simulated dimension {raster_membro.shape}.\"\n",
    "                        )\n",
    "                    fss_value = fss(raster_osservato, raster_membro, threshold, window)\n",
    "                    fss_lead_time.append(fss_value)\n",
    "                if fss_lead_time:\n",
    "                    fss_results[window][threshold].append(np.mean(fss_lead_time))\n",
    "    return fss_results\n",
    "\n",
    "results_fss = {\"LDCast\": {}, \"GPTCast\": {}}\n",
    "\n",
    "for model_name in results_fss.keys():\n",
    "    results_fss[model_name][0] = {window: {threshold: 1 for threshold in soglie} for window in finestre_spaziali}\n",
    "\n",
    "for model_name, model_dir in [(\"LDCast\", ldcast_dir), (\"GPTCast\", gptcast_dir)]:\n",
    "    observed_vector = create_observed_vector(orario_iniziale, durata_minuti, intervallo_minuti, model_dir, num_membri)\n",
    "    for lead_time in tqdm(range(5, durata_minuti + 1, intervallo_minuti), desc=f\"Lead time {model_name}\"):\n",
    "        lead_time_vector = create_lead_time_vector(orario_iniziale, durata_minuti, intervallo_minuti, lead_time, model_dir, num_membri)\n",
    "        fss_results = calculate_fss(observed_vector, lead_time_vector, finestre_spaziali, soglie)\n",
    "        results_fss[model_name][lead_time] = fss_results\n",
    "\n",
    "print(\"FSS computation completed for both models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8472c388-e254-4bf9-8b34-f2ded8b5f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "######################## FSS PLOT ###########################\n",
    "#############################################################\n",
    "\n",
    "def plot_fss(results_fss, soglia, finestra):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    colors = {\"LDCast\": \"blue\", \"GPTCast\": \"orange\"}\n",
    "    \n",
    "    for model_name, model_results in results_fss.items():\n",
    "        lead_times = sorted(model_results.keys())\n",
    "        mean_values = []\n",
    "        std_values = []\n",
    "        \n",
    "        for lead_time in lead_times:\n",
    "            fss_values = model_results[lead_time][finestra][soglia]\n",
    "            \n",
    "            if isinstance(fss_values, (int, float, np.float64)):\n",
    "                fss_values = [fss_values]\n",
    "            \n",
    "            mean_values.append(np.mean(fss_values))\n",
    "            std_values.append(np.std(fss_values))\n",
    "            \n",
    "            ax.scatter([lead_time] * len(fss_values), fss_values, color=colors[model_name], alpha=0.5, label=f\"Values {model_name}\" if lead_time == 0 else \"\")\n",
    "        \n",
    "        ax.plot(lead_times, mean_values, color=colors[model_name], label=f\"Mean {model_name}\")\n",
    "        \n",
    "        ax.fill_between(lead_times, \n",
    "                        np.array(mean_values) - np.array(std_values), \n",
    "                        np.array(mean_values) + np.array(std_values), \n",
    "                        color=colors[model_name], alpha=0.3)\n",
    "    \n",
    "    ax.set_title(f\"FSS vs Lead Time, October Case (Threshold: {soglia} mm h⁻¹, Window: {finestra} km x {finestra} km)\", fontsize=18)\n",
    "    ax.set_xlabel(\"Lead Time [min]\", fontsize=16)\n",
    "    ax.set_ylabel(\"FSS [-]\", fontsize=16)\n",
    "    ax.legend(loc=\"upper right\", fontsize=16)\n",
    "    plt.tick_params(axis=\"both\", labelsize=15)\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_fss(results_fss, soglia=2.5, finestra=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95121bf-8adb-4169-a200-169b3017902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "#################### FSS vs THRESHOLD #######################\n",
    "#############################################################\n",
    "\n",
    "def plot_fss_lines(results_fss, finestra, soglie):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    colors = {\"LDCast\": \"blue\", \"GPTCast\": \"orange\"}\n",
    "    line_styles = {0.1: \"-\", 2.5: \"--\", 10: \":\"}  \n",
    "    \n",
    "    for model_name, model_results in results_fss.items():\n",
    "        lead_times = sorted(model_results.keys())\n",
    "        \n",
    "        for threshold in soglie:\n",
    "            mean_values = []\n",
    "            \n",
    "            for lead_time in lead_times:\n",
    "                fss_values = model_results[lead_time][finestra][threshold]\n",
    "                mean_values.append(np.mean(fss_values))\n",
    "            \n",
    "            ax.plot(lead_times, mean_values, color=colors[model_name], linestyle=line_styles[threshold], marker=\"o\",\n",
    "                    label=f\"{model_name} (T = {threshold} mm h⁻¹)\")\n",
    "    \n",
    "    ax.set_title(f\"FSS vs Lead Time, October Case (Window: {finestra} km x {finestra} km)\", fontsize=18)\n",
    "    ax.set_xlabel(\"Lead Time [min]\", fontsize=16)\n",
    "    ax.set_ylabel(\"FSS [-]\", fontsize=16)\n",
    "    ax.legend(loc=\"upper right\", fontsize=14)\n",
    "    plt.tick_params(axis=\"both\", labelsize=15)\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_fss_lines(results_fss, finestra=14, soglie=[0.1, 2.5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb4381b-eaac-4bf9-8072-c1252d5545c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "################### FSS vs SPATIAL (LD) #####################\n",
    "#############################################################\n",
    "\n",
    "def plot_fss_spatial_window(results_fss, model_name, threshold, lead_times, seveso_window, y_limits=None):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    colors = {20: \"blue\", 40: \"orange\", 60: \"green\", 80: \"red\", 100: \"purple\"}  \n",
    "    line_styles = {20: \"-\", 40: \"-\", 60: \"-\", 80: \"-\", 100: \"-\"} \n",
    "    \n",
    "    model_results = results_fss[model_name]\n",
    "    spatial_windows = sorted(model_results[20].keys())  \n",
    "\n",
    "    spatial_windows = [w for w in spatial_windows if w != 8]\n",
    "    \n",
    "    for lead_time in lead_times:\n",
    "        mean_values = []\n",
    "        \n",
    "        for window in spatial_windows:\n",
    "            fss_values = model_results[lead_time][window][threshold]\n",
    "            mean_values.append(np.mean(fss_values))\n",
    "        \n",
    "        ax.plot(spatial_windows, mean_values, color=colors[lead_time], linestyle=line_styles[lead_time],\n",
    "                marker=\"o\", label=f\"Lead Time: {lead_time} min\")\n",
    "    \n",
    "    ax.axvline(x=seveso_window, color=\"red\", linestyle=\"--\", label=\"Seveso Basin\")\n",
    "    \n",
    "    ax.set_title(f\"FSS vs Spatial Window, October Case, {model_name} (Threshold: {threshold}  mm h⁻¹)\", fontsize=18)\n",
    "    ax.set_xlabel(\"Spatial Window [km x km]\", fontsize=16)\n",
    "    ax.set_ylabel(\"FSS [-]\", fontsize=16)\n",
    "    ax.set_xticks(spatial_windows)\n",
    "    ax.set_xticklabels([f\"{w}x{w}\" for w in spatial_windows], rotation=90, ha=\"right\")  \n",
    "    ax.legend(loc=\"lower right\", fontsize=15)\n",
    "    plt.tick_params(axis=\"both\", labelsize=15)\n",
    "\n",
    "    if y_limits:\n",
    "        ax.set_ylim(y_limits)\n",
    "        \n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_fss_spatial_window(results_fss, model_name=\"LDCast\", threshold=0.1, lead_times=[20, 40, 60, 80, 100], seveso_window=14, y_limits=(0, 1))\n",
    "plot_fss_spatial_window(results_fss, model_name=\"LDCast\", threshold=2.5, lead_times=[20, 40, 60, 80, 100], seveso_window=14, y_limits=(0, 1))\n",
    "plot_fss_spatial_window(results_fss, model_name=\"LDCast\", threshold=10, lead_times=[20, 40, 60, 80, 100], seveso_window=14, y_limits=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc45fc2-6d04-40af-96ed-c06faf7f8177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "################### FSS vs SPATIAL (GPT) ####################\n",
    "#############################################################\n",
    "\n",
    "def plot_fss_spatial_window(results_fss, model_name, threshold, lead_times, seveso_window, y_limits=None):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    colors = {20: \"blue\", 40: \"orange\", 60: \"green\", 80: \"red\", 100: \"purple\"}  \n",
    "    line_styles = {20: \"-\", 40: \"-\", 60: \"-\", 80: \"-\", 100: \"-\"}  \n",
    "    \n",
    "    model_results = results_fss[model_name]\n",
    "    spatial_windows = sorted(model_results[20].keys())  \n",
    "\n",
    "    spatial_windows = [w for w in spatial_windows if w != 8]\n",
    "    \n",
    "    for lead_time in lead_times:\n",
    "        mean_values = []\n",
    "        \n",
    "        for window in spatial_windows:\n",
    "            fss_values = model_results[lead_time][window][threshold]\n",
    "            mean_values.append(np.mean(fss_values))\n",
    "        \n",
    "        ax.plot(spatial_windows, mean_values, color=colors[lead_time], linestyle=line_styles[lead_time],\n",
    "                marker=\"o\", label=f\"Lead Time: {lead_time} min\")\n",
    "    \n",
    "    ax.axvline(x=seveso_window, color=\"red\", linestyle=\"--\", label=\"Seveso Basin\")\n",
    "    \n",
    "    ax.set_title(f\"FSS vs Spatial Window, October Case, {model_name} (Threshold: {threshold}  mm h⁻¹)\", fontsize=18)\n",
    "    ax.set_xlabel(\"Spatial Window [km x km]\", fontsize=16)\n",
    "    ax.set_ylabel(\"FSS [-]\", fontsize=16)\n",
    "    ax.set_xticks(spatial_windows)\n",
    "    ax.set_xticklabels([f\"{w}x{w}\" for w in spatial_windows], rotation=90, ha=\"right\")  \n",
    "    ax.legend(loc=\"lower right\", fontsize=15)\n",
    "    plt.tick_params(axis=\"both\", labelsize=15)\n",
    "\n",
    "    if y_limits:\n",
    "        ax.set_ylim(y_limits)\n",
    "        \n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_fss_spatial_window(results_fss, model_name=\"GPTCast\", threshold=0.1, lead_times=[20, 40, 60, 80, 100], seveso_window=14, y_limits=(0, 1))\n",
    "plot_fss_spatial_window(results_fss, model_name=\"GPTCast\", threshold=2.5, lead_times=[20, 40, 60, 80, 100], seveso_window=14, y_limits=(0, 1))\n",
    "plot_fss_spatial_window(results_fss, model_name=\"GPTCast\", threshold=10, lead_times=[20, 40, 60, 80, 100], seveso_window=14, y_limits=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fac7d64-b56c-42a2-ae53-e85dbc1cef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "################### RANK H COMPUTATION ######################\n",
    "#############################################################\n",
    "\n",
    "def apply_transformations(raster):\n",
    "    rotated = np.rot90(raster, k=+1, axes=(0, 1))  \n",
    "    mirrored = rotated[::-1, :]  \n",
    "    return mirrored\n",
    "\n",
    "orario_iniziale = \"2023-10-31T02:45:00\"  \n",
    "durata_minuti = 120  \n",
    "durata_calcolo = 240  \n",
    "intervallo_minuti = 5  \n",
    "num_membri = list(range(20))  \n",
    "\n",
    "ldcast_dir = Path(\"../../ens/oct_ld_ens\")\n",
    "gptcast_dir = Path(\"../../ens/oct_gpt_ens\")\n",
    "\n",
    "def find_file(directory, timestamp):\n",
    "    file_list = sorted(directory.glob(\"*.nc\"))\n",
    "    for file in file_list:\n",
    "        if timestamp in file.name:\n",
    "            return file\n",
    "    return None\n",
    "\n",
    "def create_observed_vector(orario_iniziale, durata_calcolo, intervallo_minuti, directory, num_membri):\n",
    "    observed_vector = []\n",
    "    for minuto in range(0, durata_calcolo + 1, intervallo_minuti):\n",
    "        orario_corrente = datetime.strptime(orario_iniziale, \"%Y-%m-%dT%H:%M:%S\") + timedelta(minutes=minuto)\n",
    "        file_corrente = find_file(directory, orario_corrente.strftime(\"%Y-%m-%dT%H:%M:%S\"))\n",
    "        if file_corrente is None:\n",
    "            raise ValueError(f\"No file for time: {orario_corrente}\")\n",
    "        ds_corrente = xr.open_dataset(file_corrente)\n",
    "        raster_corrente = ds_corrente[\"sequence\"].isel(timestep=3).values\n",
    "        observed_vector.append(raster_corrente)\n",
    "    return observed_vector\n",
    "\n",
    "def create_lead_time_vector(orario_iniziale, durata_calcolo, intervallo_minuti, lead_time, directory, num_membri):\n",
    "    lead_time_vector = []\n",
    "    for minuto in range(0, durata_calcolo + 1, intervallo_minuti):\n",
    "        orario_corrente = datetime.strptime(orario_iniziale, \"%Y-%m-%dT%H:%M:%S\") - timedelta(minutes=lead_time - minuto)\n",
    "        timestep_corrente = 3 + (lead_time // intervallo_minuti)\n",
    "        ensemble_stack = []\n",
    "        for membro in num_membri:\n",
    "            file_membro = directory / f\"{orario_corrente.strftime('%Y-%m-%dT%H:%M:%S')}_{membro}_utm32n.nc\"\n",
    "            if not file_membro.exists():\n",
    "                continue\n",
    "            ds_membro = xr.open_dataset(file_membro)\n",
    "            if timestep_corrente >= ds_membro[\"sequence\"].shape[0]:\n",
    "                continue\n",
    "            raster_membro = ds_membro[\"sequence\"].isel(timestep=timestep_corrente).values\n",
    "            if raster_membro.ndim == 2:  \n",
    "                raster_membro_trasformato = apply_transformations(raster_membro)\n",
    "                ensemble_stack.append({\n",
    "                    \"membro\": membro,\n",
    "                    \"timestep\": timestep_corrente,\n",
    "                    \"data\": raster_membro_trasformato\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Error: ensemble member not 2D. Shape: {raster_membro.shape}\")\n",
    "        lead_time_vector.append({\n",
    "            \"timestamp\": orario_corrente,\n",
    "            \"ensemble\": ensemble_stack\n",
    "        })\n",
    "    return lead_time_vector\n",
    "\n",
    "def calculate_rank_histogram(observed_vector, lead_time_vector):\n",
    "    rank_histogram = None  \n",
    "    for i, raster_osservato in enumerate(observed_vector):\n",
    "        ensemble_stack = []\n",
    "        for ensemble_entry in lead_time_vector[i][\"ensemble\"]:\n",
    "            raster_membro = ensemble_entry[\"data\"]\n",
    "            if raster_osservato.shape != raster_membro.shape:\n",
    "                raise ValueError(\n",
    "                    f\"Observed dimension {raster_osservato.shape} \"\n",
    "                    f\"does not correspond to simulated dimension {raster_membro.shape}.\"\n",
    "                )\n",
    "            ensemble_stack.append(raster_membro)\n",
    "        \n",
    "        if len(ensemble_stack) > 0:\n",
    "            ensemble_stack = np.stack(ensemble_stack, axis=0)\n",
    "            current_rank_histogram = rankhist(ensemble_stack, raster_osservato)\n",
    "            \n",
    "            if rank_histogram is None:\n",
    "                rank_histogram = np.zeros_like(current_rank_histogram, dtype=float)\n",
    "            \n",
    "            rank_histogram += current_rank_histogram.astype(float)  \n",
    "    \n",
    "    return rank_histogram\n",
    "\n",
    "results_rank_histogram = {\"LDCast\": {}, \"GPTCast\": {}}\n",
    "\n",
    "for model_name in results_rank_histogram.keys():\n",
    "    results_rank_histogram[model_name][0] = np.zeros(21, dtype=int)  \n",
    "\n",
    "for model_name, model_dir in [(\"LDCast\", ldcast_dir), (\"GPTCast\", gptcast_dir)]:\n",
    "    observed_vector = create_observed_vector(orario_iniziale, durata_minuti, intervallo_minuti, model_dir, num_membri)\n",
    "    for lead_time in tqdm(range(5, durata_minuti + 1, intervallo_minuti), desc=f\"Lead time {model_name}\"):\n",
    "        lead_time_vector = create_lead_time_vector(orario_iniziale, durata_minuti, intervallo_minuti, lead_time, model_dir, num_membri)\n",
    "        rank_histogram = calculate_rank_histogram(observed_vector, lead_time_vector)\n",
    "        results_rank_histogram[model_name][lead_time] = rank_histogram\n",
    "\n",
    "# Risultati finali\n",
    "print(\"Rank Histogram computation completed for both models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efa011d-470b-462d-968e-d1ef634ef66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "###################### RANK H PLOT ##########################\n",
    "#############################################################\n",
    "\n",
    "def plot_rank_histogram(results_rank_histogram, num_membri, model_name, lead_times_to_plot):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ideal_value = 1 / (num_membri + 1)  \n",
    "    x_ticks = np.arange(1, num_membri + 2) \n",
    "\n",
    "    for lead_time in lead_times_to_plot:\n",
    "        if lead_time in results_rank_histogram[model_name]:  \n",
    "            histogram = results_rank_histogram[model_name][lead_time]\n",
    "            \n",
    "            relative_frequency = histogram / np.sum(histogram)\n",
    "            \n",
    "            uniform_distribution = np.full_like(relative_frequency, ideal_value)\n",
    "            kl_divergence = entropy(relative_frequency, uniform_distribution)\n",
    "            \n",
    "            plt.plot(x_ticks, relative_frequency, label=f\"{lead_time}min: KL = {kl_divergence:.3f}\")\n",
    "\n",
    "    plt.axhline(ideal_value, color=\"black\", linestyle=\"--\", linewidth=1.5, label=\"Ideal Value\")\n",
    "\n",
    "    plt.title(f\"Rank Distribution for {model_name}, October Case\", fontsize=18)\n",
    "    plt.xlabel(\"Rank of observation\", fontsize=16)\n",
    "    plt.ylabel(\"Relative Frequency [-]\", fontsize=16)\n",
    "    plt.ylim(0.03, 0.13) \n",
    "    plt.grid()\n",
    "\n",
    "    plt.xticks(ticks=x_ticks, fontsize=16)\n",
    "\n",
    "    plt.tick_params(axis=\"y\", labelsize=16)\n",
    "\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "lead_times_to_plot = [20, 40, 60, 80, 100]\n",
    "\n",
    "plot_rank_histogram(results_rank_histogram, len(num_membri), \"LDCast\", lead_times_to_plot)\n",
    "plot_rank_histogram(results_rank_histogram, len(num_membri), \"GPTCast\", lead_times_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d8ff1-bf02-48a4-af09-f2d982194ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "################# CUM PREC COMPUTATION ######################\n",
    "#############################################################\n",
    "\n",
    "timestamp_iniziale = \"2023-10-31T02:15:00\"\n",
    "time_interval = 5  \n",
    "ensemble_members = range(20)  \n",
    "\n",
    "ldcast_dir = Path(\"../../ens/oct_ld_mean\")\n",
    "gptcast_dir = Path(\"../../ens/oct_gpt_mean\")\n",
    "\n",
    "shapefile_path = \"../../data/nodo_idraulico_shape/Bacini_OUT.shp\"\n",
    "bacini = gpd.read_file(shapefile_path)\n",
    "bacini = bacini[bacini[\"Nome_bacin\"].isin([\"SEVESO alto\", \"SEVESO medio\", \"SEVESO basso\"])]\n",
    "bacini = bacini.to_crs(\"EPSG:32632\")\n",
    "bacini_uniti = bacini.unary_union\n",
    "\n",
    "lead_times = list(range(5, 125, 5))\n",
    "\n",
    "def carica_dati_con_crs(file_path, crs=\"EPSG:32632\"):\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    if not ds.rio.crs:\n",
    "        ds = ds.rio.write_crs(crs)  \n",
    "    return ds\n",
    "\n",
    "def elabora_dati_osservati(directory, bacino, lead_times, time_interval):\n",
    "    observed_files = []\n",
    "    \n",
    "    start_time = datetime.strptime(timestamp_iniziale, \"%Y-%m-%dT%H:%M:%S\")\n",
    "    for i in range(84):  \n",
    "        current_time = start_time + timedelta(minutes=i * time_interval)\n",
    "        timestamp = current_time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "        pattern = os.path.join(directory, f\"{timestamp}_ensemble_mean_utm32n.nc\")\n",
    "        files = glob.glob(pattern)\n",
    "        if files:\n",
    "            observed_files.append(files[0])  \n",
    "        else:\n",
    "            print(f\"File not found: {pattern}\")\n",
    "\n",
    "    observed_data = []\n",
    "    for file in observed_files:\n",
    "        ds = carica_dati_con_crs(file)\n",
    "        \n",
    "        if 3 < len(ds[\"sequence\"]):\n",
    "            observed_data.append(ds[\"sequence\"].isel(timestep=3))  \n",
    "        else:\n",
    "            print(f\"Timestep 3 not available in file {file}\")\n",
    "\n",
    "    if observed_data:\n",
    "        cumulative_rainfall = calcola_pioggia_cumulata(observed_data, bacino, time_interval)\n",
    "        cumulative_rainfall = [0.0] + list(cumulative_rainfall)  \n",
    "        return cumulative_rainfall\n",
    "    else:\n",
    "        raise ValueError(\"No data.\")\n",
    "\n",
    "def elabora_dati_simulati(directory, bacino, lead_times, time_interval):\n",
    "    cumulative_rainfall = []\n",
    "    \n",
    "    for lead_time in lead_times:\n",
    "        start_time = datetime.strptime(timestamp_iniziale, \"%Y-%m-%dT%H:%M:%S\") - timedelta(minutes=lead_time)\n",
    "        \n",
    "        files = []\n",
    "        for i in range(84):  \n",
    "            current_time = start_time + timedelta(minutes=i * time_interval)\n",
    "            timestamp = current_time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "            pattern = os.path.join(directory, f\"{timestamp}_ensemble_mean_utm32n.nc\")\n",
    "            matched_files = glob.glob(pattern)\n",
    "            if matched_files:\n",
    "                files.append(matched_files[0])  \n",
    "            else:\n",
    "                print(f\"File not found: {pattern}\")\n",
    "        \n",
    "        simulated_data = []\n",
    "        timestep_offset = 3 + lead_time // time_interval  \n",
    "        for file in files:\n",
    "            simulated_ds = carica_dati_con_crs(file)\n",
    "            \n",
    "            if timestep_offset < len(simulated_ds[\"sequence\"]):\n",
    "                data = simulated_ds[\"sequence\"].isel(timestep=timestep_offset)\n",
    "                simulated_data.append(data)\n",
    "            else:\n",
    "                print(f\"Timestep {timestep_offset} non disponibile nel file {file}\")\n",
    "        \n",
    "        if simulated_data:\n",
    "            cumulative_rainfall_lead_time = calcola_pioggia_cumulata(simulated_data, bacino, time_interval)\n",
    "            cumulative_rainfall_lead_time = [0.0] + list(cumulative_rainfall_lead_time)  \n",
    "            cumulative_rainfall.append(cumulative_rainfall_lead_time)\n",
    "    \n",
    "    return cumulative_rainfall\n",
    "\n",
    "def calcola_pioggia_cumulata(data, area, time_interval):\n",
    "    cumulative_rainfall = []\n",
    "    for timestep in data:\n",
    "        masked_data = ritaglia_dati(timestep, area)\n",
    "        mean_rainfall = masked_data.mean().item()  \n",
    "        rainfall_mm = mean_rainfall * (time_interval / 60)  \n",
    "        cumulative_rainfall.append(rainfall_mm)\n",
    "    return np.cumsum(cumulative_rainfall) \n",
    "\n",
    "def ritaglia_dati(data, area):\n",
    "    mask = data.rio.clip([area], crs=\"EPSG:32632\", drop=True)\n",
    "    return mask\n",
    "\n",
    "print(\"Observed data elaboration...\")\n",
    "observed_rainfall = elabora_dati_osservati(ldcast_dir, bacini_uniti, lead_times, time_interval)\n",
    "\n",
    "print(\"LDCast - simulated data elaboration...\")\n",
    "ldcast_cumulative_rainfall = elabora_dati_simulati(ldcast_dir, bacini_uniti, lead_times, time_interval)\n",
    "\n",
    "print(\"GPTCast - simulated data elaboration...\")\n",
    "gptcast_cumulative_rainfall = elabora_dati_simulati(gptcast_dir, bacini_uniti, lead_times, time_interval)\n",
    "\n",
    "print(\"Elaboration completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81704ee-b591-4082-9671-1004e05c07ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "###################### CUM PREC PLOT ########################\n",
    "#############################################################\n",
    "\n",
    "def plot_cumulative_rainfall_dual(observed_rainfall, ldcast_rainfall, gptcast_rainfall, lead_times, timestamp_iniziale, time_interval):\n",
    "    excel_file = \"../../data/oct_cum.xlsx\"\n",
    "    df = pd.read_excel(excel_file)\n",
    "\n",
    "    if not pd.api.types.is_string_dtype(df['Cumulata']):\n",
    "        df['Cumulata'] = df['Cumulata'].astype(str)\n",
    "    \n",
    "    df['Rainfall'] = df['Cumulata'].str.replace(',', '.').astype(float)\n",
    "    df['Datetime'] = pd.to_datetime(df['date_hour'])\n",
    "    \n",
    "    start_time = datetime.strptime(timestamp_iniziale, \"%Y-%m-%dT%H:%M:%S\") + timedelta(minutes=5)\n",
    "    end_time = start_time + timedelta(minutes=7 * 60)  \n",
    "    time_axis = [start_time + timedelta(minutes=i * time_interval) for i in range(len(observed_rainfall))]\n",
    "    \n",
    "    time_axis_shifted = [t + timedelta(hours=1) for t in time_axis]\n",
    "    \n",
    "    selected_lead_times = [5, 20, 40, 60]\n",
    "    colors = ['darkturquoise', 'blue', 'orange', 'green']  \n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "    \n",
    "    axes[0].plot(time_axis_shifted, observed_rainfall, color='black', label='Observed', linewidth=2)\n",
    "    for lead_time, color in zip(selected_lead_times, colors):\n",
    "        if lead_time in lead_times:\n",
    "            index = lead_times.index(lead_time)\n",
    "            axes[0].plot(time_axis_shifted, ldcast_rainfall[index], color=color, label=f'Lead time: {lead_time} min', linewidth=1.5)\n",
    "    axes[0].plot(df['Datetime'], df['Rainfall'], color='magenta', label='Observed (ARPA)', linewidth=2, linestyle='--')\n",
    "    axes[0].set_title('LDCast (October Event)', fontsize=20, color='blue')\n",
    "    axes[0].set_ylabel('Cumulative Rainfall [mm]', fontsize=16)\n",
    "    axes[0].legend(fontsize=16)\n",
    "    axes[0].grid(True, linestyle='--', alpha=0.6)\n",
    "    axes[0].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "    axes[0].xaxis.set_major_locator(mdates.HourLocator(interval=1))\n",
    "    axes[0].tick_params(axis='y', labelsize=16)\n",
    "    axes[0].tick_params(axis='x', labelsize=16, rotation=45)\n",
    "    \n",
    "    axes[1].plot(time_axis_shifted, observed_rainfall, color='black', label='Observed', linewidth=2)\n",
    "    for lead_time, color in zip(selected_lead_times, colors):\n",
    "        if lead_time in lead_times:\n",
    "            index = lead_times.index(lead_time)\n",
    "            axes[1].plot(time_axis_shifted, gptcast_rainfall[index], color=color, label=f'Lead time: {lead_time} min', linewidth=1.5)\n",
    "    axes[1].plot(df['Datetime'], df['Rainfall'], color='magenta', label='Observed (ARPA)', linewidth=2, linestyle='--')\n",
    "    axes[1].set_title('GPTCast (October Event)', fontsize=20, color='orange')\n",
    "    axes[1].set_xlabel('Date and Hour (CEST/UTC+1)', fontsize=16)\n",
    "    axes[1].set_ylabel('Cumulative Rainfall [mm]', fontsize=16)\n",
    "    axes[1].legend(fontsize=16)\n",
    "    axes[1].grid(True, linestyle='--', alpha=0.6)\n",
    "    axes[1].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "    axes[1].xaxis.set_major_locator(mdates.HourLocator(interval=1))\n",
    "    axes[1].tick_params(axis='y', labelsize=16)\n",
    "    axes[1].tick_params(axis='x', labelsize=16, rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_cumulative_rainfall_dual(\n",
    "    observed_rainfall=observed_rainfall,\n",
    "    ldcast_rainfall=ldcast_cumulative_rainfall,\n",
    "    gptcast_rainfall=gptcast_cumulative_rainfall,\n",
    "    lead_times=lead_times,\n",
    "    timestamp_iniziale=timestamp_iniziale,\n",
    "    time_interval=time_interval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cba11b-27dd-46a3-a9d3-f2ed1a099cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "################## CUM PREC ERROR PLOT ######################\n",
    "#############################################################\n",
    "\n",
    "def calcola_errori_per_lead_time(observed, simulated, lead_times):\n",
    "    error_percentages = []\n",
    "    error_absolutes = []\n",
    "    \n",
    "    for lead_time_index in range(len(lead_times)):\n",
    "        lead_time_errors_percentage = []\n",
    "        lead_time_errors_absolute = []\n",
    "        \n",
    "        for timestep in range(len(observed)):\n",
    "            observed_value = observed[timestep]\n",
    "            simulated_value = simulated[lead_time_index][timestep]  \n",
    "            \n",
    "            error_absolute = abs(simulated_value - observed_value)\n",
    "            lead_time_errors_absolute.append(error_absolute)\n",
    "            \n",
    "            if observed_value != 0:  \n",
    "                error_percentage = abs((simulated_value - observed_value) / observed_value) * 100\n",
    "            else:\n",
    "                error_percentage = 0  \n",
    "            lead_time_errors_percentage.append(error_percentage)\n",
    "        \n",
    "        error_percentages.append(lead_time_errors_percentage)\n",
    "        error_absolutes.append(lead_time_errors_absolute)\n",
    "    \n",
    "    return error_percentages, error_absolutes\n",
    "\n",
    "ldcast_error_percentages, ldcast_error_absolutes = calcola_errori_per_lead_time(observed_rainfall, ldcast_cumulative_rainfall, lead_times)\n",
    "gptcast_error_percentages, gptcast_error_absolutes = calcola_errori_per_lead_time(observed_rainfall, gptcast_cumulative_rainfall, lead_times)\n",
    "\n",
    "def plot_error_variation_lead_times(observed_rainfall, ldcast_errors, gptcast_errors, lead_times, timestamp_iniziale, time_interval, error_type, y_limits):\n",
    "    start_time = datetime.strptime(timestamp_iniziale, \"%Y-%m-%dT%H:%M:%S\") + timedelta(minutes=15)\n",
    "    end_time = start_time + timedelta(minutes=7 * 60)  \n",
    "    time_axis = [start_time + timedelta(minutes=i * time_interval) for i in range(len(observed_rainfall))]\n",
    "    \n",
    "    time_axis_shifted = [t + timedelta(hours=1) for t in time_axis]\n",
    "    \n",
    "    selected_lead_times = [5, 20, 40, 60]\n",
    "    colors = ['darkturquoise', 'blue', 'orange', 'green']  \n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True)  \n",
    "    \n",
    "    for lead_time, color in zip(selected_lead_times, colors):\n",
    "        if lead_time in lead_times:\n",
    "            index = lead_times.index(lead_time)\n",
    "            axes[0].plot(time_axis_shifted, ldcast_errors[index], color=color, label=f'Lead time: {lead_time} min', linewidth=1.5)\n",
    "    axes[0].set_title('LDCast (October Event)', fontsize=22, color='blue')\n",
    "    axes[0].set_xlabel('Date and Hour (CEST/UTC+1)', fontsize=20)\n",
    "    axes[0].set_ylabel(f'{error_type} Error {\"[%]\" if error_type == \"Percentage\" else \"[mm]\"}', fontsize=20)  \n",
    "    axes[0].legend(fontsize=16)\n",
    "    axes[0].grid(True, linestyle='--', alpha=0.6)\n",
    "    axes[0].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "    axes[0].xaxis.set_major_locator(mdates.HourLocator(interval=1))\n",
    "    axes[0].tick_params(axis='y', labelsize=18)\n",
    "    axes[0].tick_params(axis='x', labelsize=18, rotation=90)\n",
    "    \n",
    "    for lead_time, color in zip(selected_lead_times, colors):\n",
    "        if lead_time in lead_times:\n",
    "            index = lead_times.index(lead_time)\n",
    "            axes[1].plot(time_axis_shifted, gptcast_errors[index], color=color, label=f'Lead time: {lead_time} min', linewidth=1.5)\n",
    "    axes[1].set_title('GPTCast (October Event)', fontsize=22, color='orange')\n",
    "    axes[1].set_xlabel('Date and Hour (CEST/UTC+1)', fontsize=20)\n",
    "    axes[0].set_ylabel(f'{error_type} Error {\"[%]\" if error_type == \"Percentage\" else \"[mm]\"}', fontsize=20)  # Aggiunta unità di misura\n",
    "    axes[1].legend(fontsize=16)\n",
    "    axes[1].grid(True, linestyle='--', alpha=0.6)\n",
    "    axes[1].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "    axes[1].xaxis.set_major_locator(mdates.HourLocator(interval=1))\n",
    "    axes[1].tick_params(axis='y', labelsize=18)\n",
    "    axes[1].tick_params(axis='x', labelsize=18, rotation=90)\n",
    "    \n",
    "    axes[0].set_ylim(y_limits[0])  \n",
    "    axes[1].set_ylim(y_limits[1])  \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_error_variation_lead_times(\n",
    "    observed_rainfall=observed_rainfall,\n",
    "    ldcast_errors=ldcast_error_percentages,\n",
    "    gptcast_errors=gptcast_error_percentages,\n",
    "    lead_times=lead_times,\n",
    "    timestamp_iniziale=timestamp_iniziale,\n",
    "    time_interval=time_interval,\n",
    "    error_type='Percentage',\n",
    "    y_limits=[(0, 100), (0, 100)]  \n",
    ")\n",
    "\n",
    "plot_error_variation_lead_times(\n",
    "    observed_rainfall=observed_rainfall,\n",
    "    ldcast_errors=ldcast_error_absolutes,\n",
    "    gptcast_errors=gptcast_error_absolutes,\n",
    "    lead_times=lead_times,\n",
    "    timestamp_iniziale=timestamp_iniziale,\n",
    "    time_interval=time_interval,\n",
    "    error_type='Absolute',\n",
    "    y_limits=[(0, 50), (0, 50)]  \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
